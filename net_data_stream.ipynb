{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立明确网络和损失的输出输出流以及损失的计算定义\n",
    "- by 刘道会\n",
    "- 2020-08 于重庆大学"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.应当给网络输入什么？\n",
    "输入的肯定是图像信息，但是需要原始的图像信息需要经过一些处理以及格式变换才能作为输出，其实这个过程中维度的变化倒不是很大（可能会resize），主要是经过处理后的图像所包含的信息的一些处理。\n",
    "\n",
    "因为可能会对图像进行很多操作，添加一些功能之类的，而且我们当然希望这些操作是可拓展的，所以说最好定义一个输入图像的类，然后需要什么功能就在类中为它定义函数，将最终的输出图像作为这个类一个属性，这样操作起来会非常方便。\n",
    "\n",
    "那么，就开始进行这个类的定义吧"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "肯定要建立在之前工作的基础上，所以把前面的代码中要用到的部分copy一份过来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "cornell_path = 'cornell'\n",
    "graspf = glob.glob(os.path.join(cornell_path,'*','pcd*cpos.txt'))\n",
    "graspf.sort()\n",
    "\n",
    "rgbf = [filename.replace('cpos.txt','r.png') for filename in graspf]\n",
    "depthf = [filename.replace('cpos.txt','d.tiff') for filename in graspf]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class Image:\n",
    "    '''定义一个图像类，主要功能是将原始的图像输入转化为适合网络训练的格式并根据图像处理需求完成一些其他功能'''\n",
    "    def __init__(self,img):\n",
    "        '''\n",
    "        :功能 :类初始化函数\n",
    "        :参数 :ndarray,原始图像\n",
    "        '''\n",
    "        self.img = img\n",
    "    \n",
    "    @classmethod #注意，使用cls的时候要在该函数前面加装饰器声明\n",
    "    def from_file(cls,file_path):\n",
    "        '''\n",
    "        :功能           : 从原始图片的路径对其进行载入\n",
    "        :参数 file_path : str,原始图像所在的路径\n",
    "        :返回 class     : 由指定路径的原始图片实例化的Image类\n",
    "        :备注           : 这里用到的cls方法要学习一下\n",
    "        '''\n",
    "        return cls(cv2.imread(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面这就完成了这个类的基本定义，下面对它的两种初始化方法进行测试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "[[[ True  True  True]\n",
      "  [ True  True  True]\n",
      "  [ True  True  True]\n",
      "  ...\n",
      "  [ True  True  True]\n",
      "  [ True  True  True]\n",
      "  [ True  True  True]]\n",
      "\n",
      " [[ True  True  True]\n",
      "  [ True  True  True]\n",
      "  [ True  True  True]\n",
      "  ...\n",
      "  [ True  True  True]\n",
      "  [ True  True  True]\n",
      "  [ True  True  True]]\n",
      "\n",
      " [[ True  True  True]\n",
      "  [ True  True  True]\n",
      "  [ True  True  True]\n",
      "  ...\n",
      "  [ True  True  True]\n",
      "  [ True  True  True]\n",
      "  [ True  True  True]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ True  True  True]\n",
      "  [ True  True  True]\n",
      "  [ True  True  True]\n",
      "  ...\n",
      "  [ True  True  True]\n",
      "  [ True  True  True]\n",
      "  [ True  True  True]]\n",
      "\n",
      " [[ True  True  True]\n",
      "  [ True  True  True]\n",
      "  [ True  True  True]\n",
      "  ...\n",
      "  [ True  True  True]\n",
      "  [ True  True  True]\n",
      "  [ True  True  True]]\n",
      "\n",
      " [[ True  True  True]\n",
      "  [ True  True  True]\n",
      "  [ True  True  True]\n",
      "  ...\n",
      "  [ True  True  True]\n",
      "  [ True  True  True]\n",
      "  [ True  True  True]]]\n"
     ]
    }
   ],
   "source": [
    "#第一种方法，直接传入原始图像来初始化\n",
    "img = cv2.imread(rgbf[0])\n",
    "\n",
    "class1 = Image(img)\n",
    "class2 = Image.from_file(rgbf[0])\n",
    "\n",
    "print(class1.img.shape)\n",
    "print(class2.img.shape)\n",
    "      \n",
    "print(class1.img == class2.img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面为其添加一些需要用到的预处理操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class Image:\n",
    "    '''定义一个图像类，主要功能是将原始的图像输入转化为适合网络训练的格式并根据图像处理需求完成一些其他功能'''\n",
    "    def __init__(self,img):\n",
    "        '''\n",
    "        :功能 :类初始化函数\n",
    "        :参数 :ndarray,原始图像\n",
    "        '''\n",
    "        self.img = img\n",
    "    \n",
    "    @classmethod\n",
    "    def from_file(cls,file_path):\n",
    "        '''\n",
    "        :功能           : 从原始图片的路径对其进行载入\n",
    "        :参数 file_path : str,原始图像所在的路径\n",
    "        :返回 class     : 由指定路径的原始图片实例化的Image类\n",
    "        :备注           : 这里用到的cls方法要学习一下\n",
    "        '''\n",
    "        return cls(cv2.imread(file_path))\n",
    "    \n",
    "    def img_format(self):\n",
    "        '''\n",
    "        :功能 :将原始图像转换为指定格式\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def normalize(self):\n",
    "        '''\n",
    "        :功能 :将图像像素值标准化至[0,1]范围\n",
    "        '''\n",
    "        self.img = self.img.astype('float32')/255.0\n",
    "        self.img = self.img-self.img.mean()\n",
    "        \n",
    "    def crop(self):\n",
    "        '''\n",
    "        :功能 :对图像进行裁剪操作\n",
    "        '''\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标准化之前均值为170.608\n",
      "标准化之前最大值为251，最小值为1\n",
      "标准化之后均值为0.000\n",
      "标准化之后最大值为0.315，最小值为-0.665\n"
     ]
    }
   ],
   "source": [
    "#测试标准化函数的功能：\n",
    "\n",
    "rgbclass = Image.from_file(rgbf[0])\n",
    "\n",
    "print('标准化之前均值为%.3f' % rgbclass.img.mean())\n",
    "print('标准化之前最大值为%d，最小值为%d' % (rgbclass.img.max(),rgbclass.img.min()))\n",
    "\n",
    "rgbclass.normalize()\n",
    "\n",
    "print('标准化之后均值为%.3f' % rgbclass.img.mean())\n",
    "print('标准化之后最大值为%.3f，最小值为%.3f' % (rgbclass.img.max(),rgbclass.img.min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "到此预处理结束，图像信息就可以作为网络的输入信息了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.如何设置网络的输出参数？\n",
    "网络的输出肯定是根据设置的表征参数来做的，也就是你怎么去定义一个抓取，比如这里的抓取通常使用五维信息参数（x,y,$\\theta$,width,h）h这个参数没什么意思，就是夹爪的指宽度，所以关键的信息就是四个（x,y,$\\theta$,width），我们选择这四个参数来确定一个抓取，而网络最终的预测输出要是一个抓取，那么网络最终的预测输出值就应该是这几个值的预测结果。所以，需要将现有的标注信息转化为本方法中所选择表征方法的几个参数，同时，对图像进行预处理做数据增强时应该保证这些标注也同步进行处理，因此，最好也定义一个类来对数据进行处理，功能就是将现有的标注转化为所需要的标注，同时，要有一些预处理的操作。\n",
    "\n",
    "表征抓取的方法如下图所示：\n",
    "![nihao](images/5parameters.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先还是一个一个地来，定义一个类，输入为一个抓取框的四个角点（每个点有两个坐标，所以共八个数据）信息，然后功能就是从这些点的坐标中提取出想要的信息。\n",
    "\n",
    "后面程序中所用到的(x0,y0)即对应图中的右上角点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了方便处理，这个类的输入设置为角点的坐标信息，要经过一步预先的提取，这一步上次的程序已经做过了，这里直接复制过来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2num(point):\n",
    "    '''\n",
    "    :功能  :将字符串类型存储的抓取框脚点坐标取整并以元组形式返回\n",
    "    \n",
    "    :参数  :point,字符串，以字符串形式存储的一个点的坐标\n",
    "    :返回值 :列表，包含int型抓取点数据的列表[x,y]\n",
    "    '''\n",
    "    x,y = point.split()\n",
    "    x,y = int(round(float(x))),int(round(float(y)))\n",
    "    \n",
    "    return np.array([x,y])\n",
    "\n",
    "def get_rectangles(cornell_grasp_file):\n",
    "    '''\n",
    "    :功能  :从抓取文件中提取抓取框的坐标信息\n",
    "    \n",
    "    :参数  :cornell_grap_file:字符串，指向某个抓取文件的路径\n",
    "    :返回值 :列表，包含各个抓取矩形数据的列表\n",
    "    '''\n",
    "    grasp_rectangles = []\n",
    "    with open(cornell_grasp_file,'r') as f:\n",
    "        while True:\n",
    "            grasp_rectangle = []\n",
    "            point0 = f.readline().strip()\n",
    "            if not point0:\n",
    "                break\n",
    "            point1,point2,point3 = f.readline().strip(),f.readline().strip(),f.readline().strip()\n",
    "            grasp_rectangle = np.array([str2num(point0),\n",
    "                               str2num(point1),\n",
    "                               str2num(point2),\n",
    "                               str2num(point3)])\n",
    "            grasp_rectangles.append(grasp_rectangle)\n",
    "    \n",
    "    return grasp_rectangles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(4, 2)\n",
      "[[253 320]\n",
      " [309 324]\n",
      " [307 350]\n",
      " [251 346]]\n"
     ]
    }
   ],
   "source": [
    "#测试一下这个程序的功能是否符合预期\n",
    "\n",
    "rectangles0 = get_rectangles(graspf[0])\n",
    "\n",
    "print(type(rectangles0[0]))\n",
    "print(rectangles0[0].shape)\n",
    "print(rectangles0[0])\n",
    "\n",
    "#这里可以看出，rectangles0中的每个元素都是我们需要的一个四个点数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面开始抓取框处理类的定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Grasp:\n",
    "    '''定义一个抓取框处理类，主要功能是将原始的抓取框标注信息转化为训练所定义的表征信息，如中心位置，面积角度等，并根据图像处理需求完成一些相应的其他功能'''\n",
    "    def __init__(self,points):\n",
    "        '''\n",
    "        :功能        : 类初始化函数\n",
    "        :参数 points : 2darry,定义一个抓取框的四个角点坐标信息[[x1,y1],[x2,y2],[x3,y3],[x4,x4]]\n",
    "        '''\n",
    "        self.points = points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr = Grasp(rectangles0[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[253, 320],\n",
       "       [309, 324],\n",
       "       [307, 350],\n",
       "       [251, 346]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先计算抓取矩形框中心坐标，也就是计算这四个点的x均值和y均值，这个通过一行代码就可以实现\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[280 335]\n"
     ]
    }
   ],
   "source": [
    "center = np.mean(gr.points,axis = 0).astype(np.int)\n",
    "print(center) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后计算抓取框的宽度（对应二指夹爪张开的宽度），只需要计算出对边的长度就行了，这里在前面实验的时候发现第一个点(x0,y0)到第二个点(x1,y1)，第三个点到第四个点代表的就是我们想要的机械爪张开宽度，所以，直接计算即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.142675390472796\n"
     ]
    }
   ],
   "source": [
    "x0,y0 = gr.points[0][0],gr.points[0][1]\n",
    "x1,y1 = gr.points[1][0],gr.points[1][1]\n",
    "\n",
    "dx = x0-x1\n",
    "dy = y0-y1\n",
    "\n",
    "width = np.sqrt(dx**2+dy**2)\n",
    "\n",
    "print(width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后是抓取框的长度，虽然没什么用，但还是可以计算一下，通过第二个点到第三个点之间的距离计算即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.076809620810597\n"
     ]
    }
   ],
   "source": [
    "x1,y1 = gr.points[1][0],gr.points[1][1]\n",
    "x2,y2 = gr.points[2][0],gr.points[2][1]\n",
    "\n",
    "dx = x2-x1\n",
    "dy = y2-y1\n",
    "\n",
    "length = np.sqrt(dx**2+dy**2)\n",
    "\n",
    "print(length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是角度的计算，注意是和水平方向（x轴）的夹角：\n",
    "\n",
    "这里使用np.arctan2来计算夹角，这个函数的好处是可以指定最终角度所在的象限，只需要在输入值上给上符号就行了，但注意应该把y放在前面，比如（+y,+x）代表第一象限，（-y,+x）代表第四象限，具体可以参照这个网址：https://numpy.org/doc/stable/reference/generated/numpy.arctan2.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由图，计算这个角，还是用第一个点和第二个点的数据，这里我可以确定第一个点和第二个点连成的线是一条代表夹爪张开宽度的线，但具体在那边并不能确定，因为这一点在标注的时候他们就没有注意，如下图所示，这是不画出最后一条线的抓取矩形的效果，可以一定程度上反映出抓取框标注的顺序。\n",
    "![抓取框可视化](images/uncomplete_label.png)\n",
    "\n",
    "\n",
    "此外，关于角度，即使是和x轴的夹角，同一个条线也会两个不同的结果，但是这两个角是等价的，所以取其一便好，选择与x轴正方向的夹角即可，下面的这行代码的意思就是，计算出最终的角度并将其角度转换为了与x轴正方向的夹角，我直接从gg-cnn中摘抄过来了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.07130746478529026\n"
     ]
    }
   ],
   "source": [
    "x0,y0 = gr.points[0][0],gr.points[0][1]\n",
    "x1,y1 = gr.points[1][0],gr.points[1][1]\n",
    "\n",
    "dx = x0-x1\n",
    "dy = y0-y1\n",
    "\n",
    "#我觉得这个地方给y加个负号是没有意义的，因为如上图所示，标注的情况是有很多种的，你也不知道最终dy是正是负，最后只要保证预测和标注处理方法一致就行了，当然，也可能作者有什么高见我没看懂。\n",
    "#angle = ((np.arctan2(-dy,dx) + np.pi/2) % np.pi - np.pi/2)/np.pi*180 如果要输出角度制的话就用这行代码\n",
    "angle = ((np.arctan2(-dy,dx) + np.pi/2) % np.pi - np.pi/2)\n",
    "print(angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将第一个样本的标注框可视化后，发现角度确实是一个接近0的负角度，所以结果正确"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "到这，我们用于表征一次抓取的四个参数就都提取出来了，把这几个功能集成到类里面，这块的完整代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Grasp:\n",
    "    '''定义一个抓取框处理类，主要功能是将原始的抓取框标注信息转化为训练所定义的表征信息，如中心位置，面积角度等，并根据图像处理需求完成一些相应的其他功能'''\n",
    "    def __init__(self,points):\n",
    "        '''\n",
    "        :功能        : 类初始化函数\n",
    "        :参数 points : 2darry,定义一个抓取框的四个角点坐标信息[[x1,y1],[x2,y2],[x3,y3],[x4,x4]]\n",
    "        '''\n",
    "        self.points = points\n",
    "       \n",
    "    @property#类装饰器，可以让一个类的方法以属性的方式被调用\n",
    "    def center(self):\n",
    "        '''\n",
    "        :功能          : 计算本类中所包含的抓取框的中心点\n",
    "        :返回 1darray  : 本类所包含抓取框的中心点array[x,y]\n",
    "        '''\n",
    "        center = np.mean(self.points,axis = 0).astype(np.int)\n",
    "        return center\n",
    "    \n",
    "    @property\n",
    "    def width(self):\n",
    "        '''\n",
    "        :功能          : 计算本类中所包含的抓取框手指张开宽度width\n",
    "        :返回 1darray  : 本类所包含抓取框的长度[width]\n",
    "        '''\n",
    "        #第二个点和第三个点之间的间距长度\n",
    "        dx = self.points[0][0] - self.points[1][0]\n",
    "        dy = self.points[0][1] - self.points[1][1]\n",
    "        \n",
    "        return np.sqrt(dx**2+dy**2)\n",
    "    \n",
    "    @property\n",
    "    def length(self):\n",
    "        '''\n",
    "        :功能          : 计算本类中所包含的抓取框长度(手指张开宽度width的邻边)\n",
    "        :返回 1darray  : 本类所包含抓取框的长度[length]\n",
    "        '''\n",
    "        #第二个点和第三个点之间的间距长度\n",
    "        dx = self.points[1][0] - self.points[2][0]\n",
    "        dy = self.points[1][1] - self.points[2][1]\n",
    "        \n",
    "        return np.sqrt(dx**2+dy**2)\n",
    "    \n",
    "    @property\n",
    "    def angle(self):\n",
    "        '''\n",
    "        :功能          : 计算本类中所包含的抓取框相对于x轴正方向的偏转角度\n",
    "        :返回 1darray  : 本类所包含抓取框的旋转角度（弧度值）\n",
    "        ''' \n",
    "        \n",
    "        dx = self.points[0][0] - self.points[1][0]\n",
    "        dy = self.points[0][1] - self.points[1][1]\n",
    "        \n",
    "        return (np.arctan2(-dy,dx) + np.pi/2) % np.pi - np.pi/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#下面测试定义的模型输出\n",
    "gr = Grasp(rectangles0[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([280, 335])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.142675390472796"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.076809620810597"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.07130746478529026"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.angle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.如何进行网络的损失计算\n",
    "前面已经明确了网络的输出是什么，那么要计算损失，就必须给它相应的真实值才能实现计算，而数据集中真实值的标注并不是上面的信息，所以，要将目前的真实标注信息转化或者说提炼成为这几个参数，然后再将其作为网络的target值，与预测值计算并得到损失。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "算了，前面只是理论上明确了网络的输出，并没有实际设计网络去给定了输出，所以，还是按照常规流程来，设计封装数据集，设计网络结构，最后再来损失计算，反向传播，今天把数据集搞定，开始设计网络结构，明天把全部程序跑通。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.数据集的封装\n",
    "为了可以更方便地喂入torch的网络，最好使用torh的dataset和dataloader进行封装，这个之前做过一次了，不过用的是Iterable类，这里应该使用map类，不过都差不多，那么就定义一个cornell数据集载入类如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这个类的定义过程之前在mnist数据集的过程中已经学得比较明确了，直接照搬流程，确定输入输出即可\n",
    "# 另外，这个地方的一个难点在于，需要将输入和输出都添加封装进来，因为毕竟是数据集嘛，肯定要既有输入也要有target的\n",
    "\n",
    "class Cornell(torch.utils.data.Dataset):\n",
    "    #载入cornell数据集的类\n",
    "    def __init__(self,file_dir,include_depth=True,include_rgb=False):\n",
    "        '''\n",
    "        :功能          : 数据集封装类的初始化函数，功能包括数据集读取，数据集划分，其他参数初始化等\n",
    "        :参数 file_dir : str,按照官方文档的示例和之前的经验，这里需要读入数据集，所以需要指定数据的存放路径\n",
    "        :参数 star,end : float,为了方便数据集的拆分，这里定义添加两个边界参数start,end\n",
    "        :返回 None\n",
    "        ''' \n",
    "        super(Cornell,self).__init__()\n",
    "        \n",
    "        #去指定路径载入数据集数据\n",
    "        graspf = glob.glob(os.path.join(file_dir,'*','pcd*cpos.txt'))\n",
    "        graspf.sort()\n",
    "        \n",
    "        \n",
    "        l = len(graspf)\n",
    "        if l == 0:\n",
    "            raise FileNotFoundError('没有查找到数据集，请检查路径{}'.format(file_dir))\n",
    "        \n",
    "        rgbf = [filename.replace('cpos.txt','r.png') for filename in graspf]\n",
    "        depthf = [filename.replace('cpos.txt','d.tiff') for filename in graspf]\n",
    "        \n",
    "        #按照设定的边界参数对数据进行划分并指定为类的属性\n",
    "        self.graspf = graspf[int(l*start):int(l*end)]\n",
    "        self.rgbf = rgbf[int(l*start):int(l*end)]\n",
    "        self.depthf = depthf[int(l*start):int(l*end)]\n",
    "    \n",
    "    def get_rgb(self,idx):\n",
    "        '''\n",
    "        :功能     :读取返回指定id的rgb图像\n",
    "        :参数 idx :int,要读取的数据id\n",
    "        :返回     :ndarray,处理好后的rgb图像\n",
    "        '''\n",
    "        rgb_img = Image.from_files(self.rgbf[idx])\n",
    "        rgb_img.normalize()\n",
    "        \n",
    "        return rgb_img.img\n",
    "    \n",
    "    #因为有时候只输入RGB三通道信息，所以，定义两个返回函数，一个读取RGB一个读取深度\n",
    "    def get_depth(self,idx):\n",
    "        '''\n",
    "        :功能     :读取返回指定id的depth图像\n",
    "        :参数 idx :int,要读取的数据id\n",
    "        :返回     :ndarray,处理好后的depth图像\n",
    "        '''\n",
    "        #目前这个DepthImage类还没有定义，后面仿照Image类给它定义一下\n",
    "        depth_img = DepthImage.from_files(self.rgbf[idx])\n",
    "        depth_img.normalize()\n",
    "        \n",
    "        return depth_img.img\n",
    "    \n",
    "    def get_grasp(self,idx):\n",
    "        '''\n",
    "        :功能     :读取返回指定id的抓取标注参数\n",
    "        :参数 idx :int,要读取的数据id\n",
    "        :返回     :定义一个抓取的多个参数，包括中心点，角度，宽度和长度\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        rgb_img = self.get_rgb(idx)\n",
    "        depth_img = self.get_depth(idx)\n",
    "        grasp_parama = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这里我本来的思路是直接在一个类中读入并最后通过__getitem__()返回数据集的输入和真实标注，但参考gg_cnn的写法发现他是分开写的，将输入信息的读取作为一个子类\n",
    "#看起来要清爽一些，我也就照搬了吧\n",
    "import torch\n",
    "\n",
    "#首先定义一个最终的类，它就是最后封装好的数据集类，需要继承Dataset类，所以里面要有__getitem__()函数，通过这个函数返回全部的输入值和标签值\n",
    "class Grasp_dataset(torch.utils.data.Dataset):\n",
    "    '''\n",
    "    这个类的功能是，直接调用事先设计好的数据读取接口，将数据读取出来并按照torch的方法封装后返回，如果按照我的思路，肯定就是直接在这里面读取，后面\n",
    "    直接返回了，但是，考虑到可拓展性，当我们使用不同数据集时，数据的读取函数肯定不一样，所以，这里仅声明数据的读取函数，但不对其进行详细定义，使用\n",
    "    的时候，用哪个数据集就调用哪个数据集的读取接口就行了。\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        :功能          : 初始化函数，功能包括一些参数的初始化等\n",
    "        :参数 file_dir : str,按照官方文档的示例和之前的经验，这里需要读入数据集，所以需要指定数据的存放路径\n",
    "        :参数 star,end : float,为了方便数据集的拆分，这里定义添加两个边界参数start,end\n",
    "        :返回 None\n",
    "        ''' \n",
    "    \n",
    "    def get_rgb(self,idx):\n",
    "        #这一行的意思是，正常执行功能需要定义这个get_rgb函数，但这个类里面没有指定，你需要在继承它的子类里面定义了，如果没有定义的话就会引起这个错误\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def get_depth(self,idx):\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def get_grasp(self,idx):\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试学习一下这个skimage.draw.polygon的用法，gg_cnn里面用到了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.draw import polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function polygon in module skimage.draw.draw:\n",
      "\n",
      "polygon(r, c, shape=None)\n",
      "    Generate coordinates of pixels within polygon.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    r : (N,) ndarray\n",
      "        Row coordinates of vertices of polygon.\n",
      "    c : (N,) ndarray\n",
      "        Column coordinates of vertices of polygon.\n",
      "    shape : tuple, optional\n",
      "        Image shape which is used to determine the maximum extent of output\n",
      "        pixel coordinates. This is useful for polygons that exceed the image\n",
      "        size. If None, the full extent of the polygon is used.  Must be at\n",
      "        least length 2. Only the first two values are used to determine the\n",
      "        extent of the input image.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    rr, cc : ndarray of int\n",
      "        Pixel coordinates of polygon.\n",
      "        May be used to directly index into an array, e.g.\n",
      "        ``img[rr, cc] = 1``.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from skimage.draw import polygon\n",
      "    >>> img = np.zeros((10, 10), dtype=np.uint8)\n",
      "    >>> r = np.array([1, 2, 8])\n",
      "    >>> c = np.array([1, 7, 4])\n",
      "    >>> rr, cc = polygon(r, c)\n",
      "    >>> img[rr, cc] = 1\n",
      "    >>> img\n",
      "    array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "           [0, 0, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "           [0, 0, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "           [0, 0, 0, 1, 1, 1, 0, 0, 0, 0],\n",
      "           [0, 0, 0, 1, 1, 1, 0, 0, 0, 0],\n",
      "           [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "           [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=uint8)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(polygon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从帮助文件中可以看出，这个函数的功能是根据输入的顶点坐标绘制一个多边形,返回值是该多边形内部点的坐标，同样分别以行和列坐标的形式返回\n",
    "\n",
    "必选参数有两个，一个是r，一个是c，r代表顶点的行坐标集合，c代表顶点的列坐标集合\n",
    "\n",
    "下面对这个东西的用法进行测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def draw_polygon(r,c):\n",
    "    img = np.zeros((10,10),dtype = np.uint8)#生成一个画布\n",
    "    r = np.array(r)\n",
    "    c = np.array(c)\n",
    "    \n",
    "    rr,cc = polygon(r,c)\n",
    "    img[rr,cc] = 1\n",
    "    \n",
    "    print(img)\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#先测试一下输入两个点行不行，估计是不行的，因为多边形至少三个点嘛\n",
    "draw_polygon([1,1],[2,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "竟然没有报错，但是结果也为空，说明两个点确定不了一个多边形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#测试三个点的情况\n",
    "draw_polygon([1,2,2,1],[1,1,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function imshow in module matplotlib.pyplot:\n",
      "\n",
      "imshow(X, cmap=None, norm=None, aspect=None, interpolation=None, alpha=None, vmin=None, vmax=None, origin=None, extent=None, shape=<deprecated parameter>, filternorm=1, filterrad=4.0, imlim=<deprecated parameter>, resample=None, url=None, *, data=None, **kwargs)\n",
      "    Display data as an image; i.e. on a 2D regular raster.\n",
      "    \n",
      "    The input may either be actual RGB(A) data, or 2D scalar data, which\n",
      "    will be rendered as a pseudocolor image. Note: For actually displaying\n",
      "    a grayscale image set up the color mapping using the parameters\n",
      "    ``cmap='gray', vmin=0, vmax=255``.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    X : array-like or PIL image\n",
      "        The image data. Supported array shapes are:\n",
      "    \n",
      "        - (M, N): an image with scalar data. The values are mapped to\n",
      "          colors using normalization and a colormap. See parameters *norm*,\n",
      "          *cmap*, *vmin*, *vmax*.\n",
      "        - (M, N, 3): an image with RGB values (0-1 float or 0-255 int).\n",
      "        - (M, N, 4): an image with RGBA values (0-1 float or 0-255 int),\n",
      "          i.e. including transparency.\n",
      "    \n",
      "        The first two dimensions (M, N) define the rows and columns of\n",
      "        the image.\n",
      "    \n",
      "        Out-of-range RGB(A) values are clipped.\n",
      "    \n",
      "    cmap : str or `~matplotlib.colors.Colormap`, optional\n",
      "        The Colormap instance or registered colormap name used to map\n",
      "        scalar data to colors. This parameter is ignored for RGB(A) data.\n",
      "        Defaults to :rc:`image.cmap`.\n",
      "    \n",
      "    norm : `~matplotlib.colors.Normalize`, optional\n",
      "        The `Normalize` instance used to scale scalar data to the [0, 1]\n",
      "        range before mapping to colors using *cmap*. By default, a linear\n",
      "        scaling mapping the lowest value to 0 and the highest to 1 is used.\n",
      "        This parameter is ignored for RGB(A) data.\n",
      "    \n",
      "    aspect : {'equal', 'auto'} or float, optional\n",
      "        Controls the aspect ratio of the axes. The aspect is of particular\n",
      "        relevance for images since it may distort the image, i.e. pixel\n",
      "        will not be square.\n",
      "    \n",
      "        This parameter is a shortcut for explicitly calling\n",
      "        `.Axes.set_aspect`. See there for further details.\n",
      "    \n",
      "        - 'equal': Ensures an aspect ratio of 1. Pixels will be square\n",
      "          (unless pixel sizes are explicitly made non-square in data\n",
      "          coordinates using *extent*).\n",
      "        - 'auto': The axes is kept fixed and the aspect is adjusted so\n",
      "          that the data fit in the axes. In general, this will result in\n",
      "          non-square pixels.\n",
      "    \n",
      "        If not given, use :rc:`image.aspect`.\n",
      "    \n",
      "    interpolation : str, optional\n",
      "        The interpolation method used. If *None*, :rc:`image.interpolation`\n",
      "        is used.\n",
      "    \n",
      "        Supported values are 'none', 'antialiased', 'nearest', 'bilinear',\n",
      "        'bicubic', 'spline16', 'spline36', 'hanning', 'hamming', 'hermite',\n",
      "        'kaiser', 'quadric', 'catrom', 'gaussian', 'bessel', 'mitchell',\n",
      "        'sinc', 'lanczos'.\n",
      "    \n",
      "        If *interpolation* is 'none', then no interpolation is performed\n",
      "        on the Agg, ps, pdf and svg backends. Other backends will fall back\n",
      "        to 'nearest'. Note that most SVG renders perform interpolation at\n",
      "        rendering and that the default interpolation method they implement\n",
      "        may differ.\n",
      "    \n",
      "        If *interpolation* is the default 'antialiased', then 'nearest'\n",
      "        interpolation is used if the image is upsampled by more than a\n",
      "        factor of three (i.e. the number of display pixels is at least\n",
      "        three times the size of the data array).  If the upsampling rate is\n",
      "        smaller than 3, or the image is downsampled, then 'hanning'\n",
      "        interpolation is used to act as an anti-aliasing filter, unless the\n",
      "        image happens to be upsampled by exactly a factor of two or one.\n",
      "    \n",
      "        See\n",
      "        :doc:`/gallery/images_contours_and_fields/interpolation_methods`\n",
      "        for an overview of the supported interpolation methods, and\n",
      "        :doc:`/gallery/images_contours_and_fields/image_antialiasing` for\n",
      "        a discussion of image antialiasing.\n",
      "    \n",
      "        Some interpolation methods require an additional radius parameter,\n",
      "        which can be set by *filterrad*. Additionally, the antigrain image\n",
      "        resize filter is controlled by the parameter *filternorm*.\n",
      "    \n",
      "    alpha : scalar or array-like, optional\n",
      "        The alpha blending value, between 0 (transparent) and 1 (opaque).\n",
      "        If *alpha* is an array, the alpha blending values are applied pixel\n",
      "        by pixel, and *alpha* must have the same shape as *X*.\n",
      "    \n",
      "    vmin, vmax : scalar, optional\n",
      "        When using scalar data and no explicit *norm*, *vmin* and *vmax*\n",
      "        define the data range that the colormap covers. By default,\n",
      "        the colormap covers the complete value range of the supplied\n",
      "        data. *vmin*, *vmax* are ignored if the *norm* parameter is used.\n",
      "    \n",
      "    origin : {'upper', 'lower'}, optional\n",
      "        Place the [0, 0] index of the array in the upper left or lower left\n",
      "        corner of the axes. The convention 'upper' is typically used for\n",
      "        matrices and images.\n",
      "        If not given, :rc:`image.origin` is used, defaulting to 'upper'.\n",
      "    \n",
      "        Note that the vertical axes points upward for 'lower'\n",
      "        but downward for 'upper'.\n",
      "    \n",
      "        See the :doc:`/tutorials/intermediate/imshow_extent` tutorial for\n",
      "        examples and a more detailed description.\n",
      "    \n",
      "    extent : scalars (left, right, bottom, top), optional\n",
      "        The bounding box in data coordinates that the image will fill.\n",
      "        The image is stretched individually along x and y to fill the box.\n",
      "    \n",
      "        The default extent is determined by the following conditions.\n",
      "        Pixels have unit size in data coordinates. Their centers are on\n",
      "        integer coordinates, and their center coordinates range from 0 to\n",
      "        columns-1 horizontally and from 0 to rows-1 vertically.\n",
      "    \n",
      "        Note that the direction of the vertical axis and thus the default\n",
      "        values for top and bottom depend on *origin*:\n",
      "    \n",
      "        - For ``origin == 'upper'`` the default is\n",
      "          ``(-0.5, numcols-0.5, numrows-0.5, -0.5)``.\n",
      "        - For ``origin == 'lower'`` the default is\n",
      "          ``(-0.5, numcols-0.5, -0.5, numrows-0.5)``.\n",
      "    \n",
      "        See the :doc:`/tutorials/intermediate/imshow_extent` tutorial for\n",
      "        examples and a more detailed description.\n",
      "    \n",
      "    filternorm : bool, optional, default: True\n",
      "        A parameter for the antigrain image resize filter (see the\n",
      "        antigrain documentation).  If *filternorm* is set, the filter\n",
      "        normalizes integer values and corrects the rounding errors. It\n",
      "        doesn't do anything with the source floating point values, it\n",
      "        corrects only integers according to the rule of 1.0 which means\n",
      "        that any sum of pixel weights must be equal to 1.0.  So, the\n",
      "        filter function must produce a graph of the proper shape.\n",
      "    \n",
      "    filterrad : float > 0, optional, default: 4.0\n",
      "        The filter radius for filters that have a radius parameter, i.e.\n",
      "        when interpolation is one of: 'sinc', 'lanczos' or 'blackman'.\n",
      "    \n",
      "    resample : bool, optional\n",
      "        When *True*, use a full resampling method.  When *False*, only\n",
      "        resample when the output image is larger than the input image.\n",
      "    \n",
      "    url : str, optional\n",
      "        Set the url of the created `.AxesImage`. See `.Artist.set_url`.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    image : `~matplotlib.image.AxesImage`\n",
      "    \n",
      "    Other Parameters\n",
      "    ----------------\n",
      "    **kwargs : `~matplotlib.artist.Artist` properties\n",
      "        These parameters are passed on to the constructor of the\n",
      "        `.AxesImage` artist.\n",
      "    \n",
      "    See also\n",
      "    --------\n",
      "    matshow : Plot a matrix or an array as an image.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Unless *extent* is used, pixel centers will be located at integer\n",
      "    coordinates. In other words: the origin will coincide with the center\n",
      "    of pixel (0, 0).\n",
      "    \n",
      "    There are two common representations for RGB images with an alpha\n",
      "    channel:\n",
      "    \n",
      "    -   Straight (unassociated) alpha: R, G, and B channels represent the\n",
      "        color of the pixel, disregarding its opacity.\n",
      "    -   Premultiplied (associated) alpha: R, G, and B channels represent\n",
      "        the color of the pixel, adjusted for its opacity by multiplication.\n",
      "    \n",
      "    `~matplotlib.pyplot.imshow` expects RGB images adopting the straight\n",
      "    (unassociated) alpha representation.\n",
      "    \n",
      "    .. note::\n",
      "        In addition to the above described arguments, this function can take a\n",
      "        **data** keyword argument. If such a **data** argument is given, the\n",
      "        following arguments are replaced by **data[<arg>]**:\n",
      "    \n",
      "        * All positional and all keyword arguments.\n",
      "    \n",
      "        Objects passed as **data** must support item access (``data[<arg>]``) and\n",
      "        membership test (``<arg> in data``).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(plt.imshow)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
