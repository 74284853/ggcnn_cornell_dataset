{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练的提速\n",
    "实际训练后发现，速度没有预想得那么快，打开GPU性能窗口发现大多数时间GPU只是显存占用，算力占用为0,而CPU确实占满了的。\n",
    "[GPU](../images/GPU.png)，经过测试和查阅资料，发现是因为CPU的读取速度过慢导致跟不上GPU的运算，进而使得大部分时间都是消耗在CPU调用数据，GPU都是闲置的，如果只有我的电脑这样倒也没啥，可能说明我的CPU比较垃圾，但是在kaggle上的测试也是这样[kaggle](../images/kaggle.png)，进一步查阅资料和测试发现，合理设置num_workers可以缓解这一问题，不同num_workers的耗时对比见下图[time_consume_w.png](../images/time_consume_w.png),可以看到，训练的时间基本都是稳定的，占比很小，占大头的都是进入和退出for循环和epoch，这个都是CPU读取数据的耗时，下面测试各种优化方法，看看哪种有效。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.设置不同的num_workers\n",
    "\n",
    "设置不同的num_workers确实可以影响，但是其他参数变了之后这个好像也要重新选，在batch_size = 32的情况下，测试不同batch_size的影响如下图所示：\n",
    "在cornell上的测试结果：\n",
    "\n",
    "[time_consume_c.png](../images/time_consume_c.png)\n",
    "\n",
    "在jacquard上的测试结果：\n",
    "\n",
    "[time_consume_j.png](../images/time_consume_j.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.使用dali库\n",
    "NVIDIA DALI（R）是NVIDIA的数据加载库，它是高度优化的构建基块和执行引擎的集合，可加速深度学习应用程序输入数据的预处理。DALI提供了性能和灵活性，可以作为一个库来加速不同的数据管道。然后可以将该库轻松集成到不同的深度学习训练和推理应用程序中。\n",
    "\n",
    "主要就是想了利用它从磁盘批量读取图像文件并转换成Tensor文件，同时可以执行一定的增强操作。\n",
    "\n",
    "下面按照官方的例程来试一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Pipeline in module nvidia.dali.pipeline:\n",
      "\n",
      "class Pipeline(builtins.object)\n",
      " |  Pipeline class is the base of all DALI data pipelines. The pipeline\n",
      " |  encapsulates the data processing graph and the execution engine.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  `batch_size` : int, optional, default = -1\n",
      " |      Batch size of the pipeline. Negative values for this parameter\n",
      " |      are invalid - the default value may only be used with\n",
      " |      serialized pipeline (the value stored in serialized pipeline\n",
      " |      is used instead).\n",
      " |  `num_threads` : int, optional, default = -1\n",
      " |      Number of CPU threads used by the pipeline.\n",
      " |      Negative values for this parameter are invalid - the default\n",
      " |      value may only be used with serialized pipeline (the value\n",
      " |      stored in serialized pipeline is used instead).\n",
      " |  `device_id` : int, optional, default = -1\n",
      " |      Id of GPU used by the pipeline.\n",
      " |      A None value for this parameter means that DALI should not use GPU nor CUDA runtime.\n",
      " |      This limits the pipeline to only CPU operators but allows it to run on any CPU capable machine.\n",
      " |  `seed` : int, optional, default = -1\n",
      " |      Seed used for random number generation. Leaving the default value\n",
      " |      for this parameter results in random seed.\n",
      " |  `exec_pipelined` : bool, optional, default = True\n",
      " |      Whether to execute the pipeline in a way that enables\n",
      " |      overlapping CPU and GPU computation, typically resulting\n",
      " |      in faster execution speed, but larger memory consumption.\n",
      " |  `prefetch_queue_depth` : int or {\"cpu_size\": int, \"gpu_size\": int}, optional, default = 2\n",
      " |      Depth of the executor pipeline. Deeper pipeline makes DALI\n",
      " |      more resistant to uneven execution time of each batch, but it\n",
      " |      also consumes more memory for internal buffers.\n",
      " |      Specifying a dict:\n",
      " |      ``{ \"cpu_size\": x, \"gpu_size\": y }``\n",
      " |      instead of an integer will cause the pipeline to use separated\n",
      " |      queues executor, with buffer queue size `x` for cpu stage\n",
      " |      and `y` for mixed and gpu stages. It is not supported when both `exec_async`\n",
      " |      and `exec_pipelined` are set to `False`.\n",
      " |      Executor will buffer cpu and gpu stages separatelly,\n",
      " |      and will fill the buffer queues when the first :meth:`run`\n",
      " |      is issued.\n",
      " |  `exec_async` : bool, optional, default = True\n",
      " |      Whether to execute the pipeline asynchronously.\n",
      " |      This makes :meth:`run` method\n",
      " |      run asynchronously with respect to the calling Python thread.\n",
      " |      In order to synchronize with the pipeline one needs to call\n",
      " |      :meth:`outputs` method.\n",
      " |  `bytes_per_sample` : int, optional, default = 0\n",
      " |      A hint for DALI for how much memory to use for its tensors.\n",
      " |  `set_affinity` : bool, optional, default = False\n",
      " |      Whether to set CPU core affinity to the one closest to the\n",
      " |      GPU being used.\n",
      " |  `max_streams` : int, optional, default = -1\n",
      " |      Limit the number of CUDA streams used by the executor.\n",
      " |      Value of -1 does not impose a limit.\n",
      " |      This parameter is currently unused (and behavior of\n",
      " |      unrestricted number of streams is assumed).\n",
      " |  `default_cuda_stream_priority` : int, optional, default = 0\n",
      " |      CUDA stream priority used by DALI. See `cudaStreamCreateWithPriority` in CUDA documentation\n",
      " |  `enable_memory_stats`: bool, optional, default = False\n",
      " |      If DALI should print operator output buffer statistics.\n",
      " |      Usefull for `bytes_per_sample_hint` operator parameter.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __enter__(self)\n",
      " |      Safely sets the pipeline as current.\n",
      " |      Current pipeline is required to call operators with side effects or without outputs.\n",
      " |      Examples of such operators are `PythonFunction` (potential side effects) or `DumpImage`\n",
      " |      (no output).\n",
      " |      \n",
      " |      Any dangling operator can be marked as having side effects if it's marked\n",
      " |      with `preserve=True`, which can be useful for debugging - otherwise operator which\n",
      " |      does not contribute to the pipeline output is removed from the graph.\n",
      " |      \n",
      " |      To manually set new (and restore previous) current pipeline, use :meth:`push_current`\n",
      " |      and :meth:`pop_current`, respectively.\n",
      " |  \n",
      " |  __exit__(self, exception_type, exception_value, traceback)\n",
      " |      Safely restores previous pipeline.\n",
      " |  \n",
      " |  __init__(self, batch_size=-1, num_threads=-1, device_id=-1, seed=-1, exec_pipelined=True, prefetch_queue_depth=2, exec_async=True, bytes_per_sample=0, set_affinity=False, max_streams=-1, default_cuda_stream_priority=0, *, enable_memory_stats=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  add_sink(self, edge)\n",
      " |      Allows to manual add of graph edges to the pipeline which are not connected to the output and all pruned\n",
      " |  \n",
      " |  build(self, define_graph=None)\n",
      " |      Build the pipeline.\n",
      " |      \n",
      " |      Pipeline needs to be built in order to run it standalone.\n",
      " |      Framework-specific plugins handle this step automatically.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      define_graph : callable\n",
      " |          If specified, this function will be used instead of member :meth:`define_graph`.\n",
      " |          This parameter must not be set, if the pipeline outputs are specified with\n",
      " |          :meth:`set_outputs`.\n",
      " |  \n",
      " |  define_graph(self)\n",
      " |      This function is defined by the user to construct the\n",
      " |      graph of operations for their pipeline.\n",
      " |      \n",
      " |      It returns a list of outputs created by calling DALI Operators.\n",
      " |  \n",
      " |  deserialize_and_build(self, serialized_pipeline)\n",
      " |      Deserialize and build the pipeline given in serialized form.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      serialized_pipeline : str\n",
      " |                            Serialized pipeline.\n",
      " |  \n",
      " |  empty(self)\n",
      " |      If there is any work scheduled in the pipeline but not yet consumed\n",
      " |  \n",
      " |  enable_api_check(self, enable)\n",
      " |      Allows to enable or disable API check in the runtime\n",
      " |  \n",
      " |  epoch_size(self, name=None)\n",
      " |      Epoch size of a pipeline.\n",
      " |      \n",
      " |      If the `name` parameter is `None`, returns a dictionary of pairs\n",
      " |      `(reader name, epoch size for that reader)`.\n",
      " |      If the `name` parameter is not `None`, returns epoch size for that\n",
      " |      reader.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : str, optional, default = None\n",
      " |          The reader which should be used to obtain epoch size.\n",
      " |  \n",
      " |  executor_statistics(self)\n",
      " |      Returns provided pipeline executor statistics metadata as a dictionary.\n",
      " |      Each key in the dictionary is the operator name. To enable it use ``executor_statistics``\n",
      " |      \n",
      " |      Available metadata keys for each operator:\n",
      " |      \n",
      " |      ``real_memory_size``:     list of memory sizes that is used by each output of the operator;\n",
      " |                                index in the list corresponds to the output index\n",
      " |      \n",
      " |      ``max_real_memory_size``: list of maximum tensor size that is used by each output of the operator;\n",
      " |                                index in the list corresponds to the output index\n",
      " |      \n",
      " |      ``reserved_memory_size``: list of memory sizes that is reserved for each of the operator outputs\n",
      " |                                index in the list corresponds to the output index\n",
      " |      \n",
      " |      ``max_reserved_memory_size``: list of maximum memory sizes per tensor that is reserved for each of the operator outputs\n",
      " |                                index in the list corresponds to the output index\n",
      " |  \n",
      " |  feed_input(self, data_node, data, layout=None, cuda_stream=None, use_copy_kernel=False)\n",
      " |      Pass a mutlidimensional array or DLPack (or a list thereof) to an output of ExternalSource.\n",
      " |      In the case of the GPU input, the data must be modified on the same stream as the one\n",
      " |      used by feed_input. See ``cuda_stream`` parameter for details.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data_node : :class:`DataNode` or str\n",
      " |          The name of the :class:`nvidia.dali.ops.ExternalSource` node or a :class:`DataNode`\n",
      " |          object returned by a call to that ExternalSource.\n",
      " |      \n",
      " |      data : an ndarray or DLPack or a list thereof\n",
      " |          The array(s) may be one of:\n",
      " |            * NumPy ndarray (CPU)\n",
      " |            * MXNet ndarray (CPU)\n",
      " |            * PyTorch tensor (CPU or GPU)\n",
      " |            * CuPy array (GPU)\n",
      " |            * objects implementing ``__cuda_array_interface__``\n",
      " |            * DALI `TensorList` or list of DALI `Tensor` objects\n",
      " |      \n",
      " |          The data to be used as the output of the ExternalSource referred to by `data_node`.\n",
      " |      \n",
      " |      layout : str or None\n",
      " |          The description of the data layout (or empty string, if not specified).\n",
      " |          It should be a string of the length that matches the dimensionality of the data, batch\n",
      " |          dimension excluded. For a batch of channel-first images, this should be \"CHW\", for\n",
      " |          channel-last video it's \"FHWC\" and so on.\n",
      " |          If ``data`` is a DALI `TensorList` or a list of DALI `Tensor` objects and ``layout``\n",
      " |          is ``None``, the layout is taken from ``data``.\n",
      " |      \n",
      " |      cuda_stream : optional, `cudaStream_t` or an object convertible to `cudaStream_t`, e.g. `cupy.cuda.Stream`, `torch.cuda.Stream`\n",
      " |          The CUDA stream, which is going to be used for copying data to GPU or from a GPU\n",
      " |          source. If not set, best effort will be taken to maintain correctness - i.e. if the data\n",
      " |          is provided as a tensor/array from a recognized library (CuPy, PyTorch), the library's\n",
      " |          current stream is used. This should work in typical scenarios, but advanced use cases\n",
      " |          (and code using unsupported libraries) may still need to supply the stream handle\n",
      " |          explicitly.\n",
      " |      \n",
      " |          Special values:\n",
      " |            *  0 - use default CUDA stream\n",
      " |            * -1 - use DALI's internal stream\n",
      " |      \n",
      " |          If internal stream is used, the call to ``feed_input`` will block until the copy to\n",
      " |          internal buffer is complete, since there's no way to synchronize with this stream to\n",
      " |          prevent overwriting the array with new data in another stream.\n",
      " |      \n",
      " |      use_copy_kernel : optional, `bool`\n",
      " |          If set to True, DALI will use a CUDA kernel to feed the data (only applicable when copying\n",
      " |          data to/from GPU memory) instead of cudaMemcpyAsync (default).\n",
      " |  \n",
      " |  iter_setup(self)\n",
      " |      This function can be overriden by user-defined\n",
      " |      pipeline to perform any needed setup for each iteration.\n",
      " |      For example, one can use this function to feed the input\n",
      " |      data from NumPy arrays.\n",
      " |  \n",
      " |  outputs(self)\n",
      " |      Returns the outputs of the pipeline and releases previous buffer.\n",
      " |      \n",
      " |      If the pipeline is executed asynchronously, this function blocks\n",
      " |      until the results become available. It rises StopIteration if data set\n",
      " |      reached its end - usually when iter_setup cannot produce any more data.\n",
      " |      \n",
      " |      :return:\n",
      " |          A list of `TensorList` objects for respective pipeline outputs\n",
      " |  \n",
      " |  reader_meta(self, name=None)\n",
      " |      Returns provided reader metadata as a dictionary. If no name is provided if provides\n",
      " |      a dictionary with data for all readers as {reader_name : meta}\n",
      " |      \n",
      " |      Available metadata keys:\n",
      " |      \n",
      " |      ``epoch_size``:        raw epoch size\n",
      " |      \n",
      " |      ``epoch_size_padded``: epoch size with the padding at the end to be divisible by the number of shards\n",
      " |      \n",
      " |      ``number_of_shards``:  number of shards\n",
      " |      \n",
      " |      ``shard_id``:          shard id of given reader\n",
      " |      \n",
      " |      ``pad_last_batch``:    if given reader should pad last batch\n",
      " |      \n",
      " |      ``stick_to_shard``:    if given reader should stick to its shard\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : str, optional, default = None\n",
      " |          The reader which should be used to obtain shards_number.\n",
      " |  \n",
      " |  release_outputs(self)\n",
      " |      Release buffers returned by share_outputs calls.\n",
      " |      \n",
      " |      It helps in case when output call result is consumed (copied)\n",
      " |      and buffers can be marked as free before the next call to share_outputs. It provides\n",
      " |      the user with better control about when he wants to run the pipeline, when he wants\n",
      " |      to obtain the resulting buffers and when they can be returned to DALI pool when the\n",
      " |      results have been consumed.\n",
      " |      Needs to be used together with :meth:`schedule_run`\n",
      " |      and :meth:`share_outputs`\n",
      " |      Should not be mixed with :meth:`run` in the same pipeline\n",
      " |  \n",
      " |  reset(self)\n",
      " |      Resets pipeline iterator\n",
      " |      \n",
      " |      If pipeline iterator reached the end then reset its state to the beginning.\n",
      " |  \n",
      " |  run(self)\n",
      " |      Run the pipeline and return the result.\n",
      " |      \n",
      " |      If the pipeline was created with `exec_pipelined` option set to `True`,\n",
      " |      this function will also start prefetching the next iteration for\n",
      " |      faster execution.\n",
      " |      Should not be mixed with :meth:`schedule_run` in the same pipeline,\n",
      " |      :meth:`share_outputs` and\n",
      " |      :meth:`release_outputs`\n",
      " |      \n",
      " |      :return:\n",
      " |          A list of `TensorList` objects for respective pipeline outputs\n",
      " |  \n",
      " |  save_graph_to_dot_file(self, filename, show_tensors=False, show_ids=False, use_colors=False)\n",
      " |      Saves the pipeline graph to a file.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      filename : str\n",
      " |                 Name of the file to which the graph is written.\n",
      " |      show_tensors : bool\n",
      " |                 Show the Tensor nodes in the graph (by default only Operator nodes are shown)\n",
      " |      show_ids : bool\n",
      " |                 Add the node id to the graph representation\n",
      " |      use_colors : bool\n",
      " |                 Whether use color to distinguish stages\n",
      " |  \n",
      " |  schedule_run(self)\n",
      " |      Run the pipeline without returning the resulting buffers.\n",
      " |      \n",
      " |      If the pipeline was created with `exec_pipelined` option set to `True`,\n",
      " |      this function will also start prefetching the next iteration for\n",
      " |      faster execution. It provides better control to the users about when they\n",
      " |      want to run the pipeline, when they want to obtain resulting buffers\n",
      " |      and return them to DALI buffer pool when the results have been consumed.\n",
      " |      Needs to be used together with :meth:`release_outputs`\n",
      " |      and :meth:`share_outputs`.\n",
      " |      Should not be mixed with :meth:`run` in the same pipeline\n",
      " |  \n",
      " |  serialize(self, define_graph=None, filename=None)\n",
      " |      Serialize the pipeline to a Protobuf string.\n",
      " |      \n",
      " |      Additionally, you can pass file name, so that serialized pipeline will be written there.\n",
      " |      The file contents will be overwritten\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      define_graph : allable\n",
      " |              If specified, this function will be used instead of member :meth:`define_graph`.\n",
      " |              This parameter must not be set, if the pipeline outputs are specified with\n",
      " |              :meth:`set_outputs`.\n",
      " |      filename : str\n",
      " |              File, from where serialized pipeline will be writeen.\n",
      " |      kwargs : dict\n",
      " |              Refer to Pipeline constructor for full list of arguments.\n",
      " |  \n",
      " |  set_outputs(self, *output_data_nodes)\n",
      " |      Set the outputs of the pipeline.\n",
      " |      \n",
      " |      Use of this function is an alternative to overriding `define_graph` in a derived class.\n",
      " |      \n",
      " |      Args\n",
      " |      ----\n",
      " |      `*output_data_nodes` : unpacked list of :class:`DataNode` objects\n",
      " |          The outputs of the pipeline\n",
      " |  \n",
      " |  share_outputs(self)\n",
      " |      Returns the outputs of the pipeline.\n",
      " |      \n",
      " |      Main difference to :meth:`outputs`\n",
      " |      is that share_outputs doesn't release returned buffers, release_outputs\n",
      " |      need to be called for that. If the pipeline is executed asynchronously,\n",
      " |      this function blocks until the results become available. It provides\n",
      " |      the user with better control about when he wants to run the pipeline, when he wants\n",
      " |      to obtain the resulting buffers and when they can be returned to DALI pool when the\n",
      " |      results have been consumed.\n",
      " |      Needs to be used together with :meth:`release_outputs`\n",
      " |      and :meth:`schedule_run`\n",
      " |      Should not be mixed with :meth:`run` in the same pipeline.\n",
      " |      \n",
      " |      :return:\n",
      " |          A list of `TensorList` objects for respective pipeline outputs\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  deserialize(serialized_pipeline=None, filename=None, **kwargs) from builtins.type\n",
      " |      Deserialize and build pipeline.\n",
      " |      \n",
      " |      Deserialize pipeline, previously serialized with ``serialize()`` method.\n",
      " |      \n",
      " |      Returned pipeline is already built.\n",
      " |      \n",
      " |      Alternatively, additional arguments can be passed, which will be used when instantiating\n",
      " |      the pipeline. Refer to Pipeline constructor for full list of arguments. By default,\n",
      " |      the pipeline will be instantiated with the arguments from serialized pipeline.\n",
      " |      \n",
      " |      Note, that ``serialized_pipeline`` and ``filename`` parameters are mutually exclusive\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      serialized_pipeline : str\n",
      " |                 Pipeline, serialized using ``serialize()`` method.\n",
      " |      filename : str\n",
      " |                 File, from which serialized pipeline will be read.\n",
      " |      kwargs : dict\n",
      " |                 Refer to Pipeline constructor for full list of arguments.\n",
      " |      \n",
      " |      Returns\n",
      " |      ----------\n",
      " |      Deserialized and built pipeline.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  current()\n",
      " |  \n",
      " |  pop_current()\n",
      " |      Restores previous pipeline as current. Complementary to :meth:`push_current`.\n",
      " |  \n",
      " |  push_current(pipeline)\n",
      " |      Sets the pipeline as current and stores the previous current pipeline\n",
      " |      on stack. To restore previous pipeline as current, use :meth:`pop_current`.\n",
      " |      \n",
      " |      To make sure that the pipeline is properly restored in case of exception, use context\n",
      " |      manager (`with my_pipeline:`).\n",
      " |      \n",
      " |      Current pipeline is required to call operators with side effects or without outputs.\n",
      " |      Examples of such operators are `PythonFunction` (potential side effects) or `DumpImage`\n",
      " |      (no output).\n",
      " |      \n",
      " |      Any dangling operator can be marked as having side effects if it's marked\n",
      " |      with `preserve=True`, which can be useful for debugging - otherwise operator which\n",
      " |      does not contribute to the pipeline output is removed from the graph.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  batch_size\n",
      " |      Batch size.\n",
      " |  \n",
      " |  device_id\n",
      " |      Id of the GPU used by the pipeline.\n",
      " |  \n",
      " |  exec_async\n",
      " |  \n",
      " |  exec_pipelined\n",
      " |  \n",
      " |  num_threads\n",
      " |      Number of CPU threads used by the pipeline.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nvidia.dali.pipeline import Pipeline\n",
    "\n",
    "help(Pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "test_data_root = os.environ['DALI_EXTRA_PATH']\n",
    "\n",
    "# Caffe LMDB\n",
    "lmdb_folder = os.path.join(test_data_root, 'db', 'lmdb')\n",
    "\n",
    "N = 8             # number of GPUs\n",
    "BATCH_SIZE = 128  # batch size per GPU\n",
    "ITERATIONS = 32\n",
    "IMAGE_SIZE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nvidia.dali.pipeline import Pipeline\n",
    "import nvidia.dali.ops as ops\n",
    "import nvidia.dali.types as types\n",
    "\n",
    "class CaffeReadPipeline(Pipeline):\n",
    "    def __init__(self, batch_size, num_threads, device_id, num_gpus):\n",
    "        super(CaffeReadPipeline, self).__init__(batch_size, num_threads, device_id)\n",
    "\n",
    "        self.input = ops.CaffeReader(path = lmdb_folder,\n",
    "                                     random_shuffle = True, shard_id = device_id, num_shards = num_gpus)\n",
    "        self.decode = ops.ImageDecoder(device = \"mixed\", output_type = types.RGB)\n",
    "        self.resize = ops.Resize(device = \"gpu\",\n",
    "                                 interp_type = types.INTERP_LINEAR)\n",
    "        self.cmn = ops.CropMirrorNormalize(device = \"gpu\",\n",
    "                                            dtype = types.FLOAT,\n",
    "                                            crop = (227, 227),\n",
    "                                            mean = [128., 128., 128.],\n",
    "                                            std = [1., 1., 1.])\n",
    "        self.uniform = ops.Uniform(range = (0.0, 1.0))\n",
    "        self.resize_rng = ops.Uniform(range = (256, 480))\n",
    "\n",
    "    def define_graph(self):\n",
    "        inputs, labels = self.input(name=\"Reader\")\n",
    "        images = self.decode(inputs)\n",
    "        images = self.resize(images, resize_shorter = self.resize_rng())\n",
    "        output = self.cmn(images, crop_pos_x = self.uniform(),\n",
    "                          crop_pos_y = self.uniform())\n",
    "        return (output, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Critical error when building pipeline:\nError when constructing operator: CaffeReader encountered:\n[/opt/dali/dali/operators/reader/loader/lmdb.h:52] Assert on \"mdb_env_open(mdb_env_, path.c_str(), mdb_flags, 0664) == 0\" failed: LMDB Error: Invalid argument, with file: /opt/dali_extra/db/lmdb\nStacktrace (100 entries):\n[frame 0]: /home/ldh/anaconda3/envs/gg_cnn/lib/python3.6/site-packages/nvidia/dali/libdali_operators.so(+0x3cf8ee) [0x7fa7aa7218ee]\n[frame 1]: /home/ldh/anaconda3/envs/gg_cnn/lib/python3.6/site-packages/nvidia/dali/libdali_operators.so(+0x182a83b) [0x7fa7abb7c83b]\n[frame 2]: /home/ldh/anaconda3/envs/gg_cnn/lib/python3.6/site-packages/nvidia/dali/libdali_operators.so(+0x1830cc9) [0x7fa7abb82cc9]\n[frame 3]: /home/ldh/anaconda3/envs/gg_cnn/lib/python3.6/site-packages/nvidia/dali/libdali_operators.so(std::_Function_handler<std::unique_ptr<dali::OperatorBase, std::default_delete<dali::OperatorBase> > (dali::OpSpec const&), std::unique_ptr<dali::OperatorBase, std::default_delete<dali::OperatorBase> > (*)(dali::OpSpec const&)>::_M_invoke(std::_Any_data const&, dali::OpSpec const&)+0xc) [0x7fa7aa7196bc]\n[frame 4]: /home/ldh/anaconda3/envs/gg_cnn/lib/python3.6/site-packages/nvidia/dali/libdali.so(+0x18b9e4) [0x7fa7dc6ea9e4]\n[frame 5]: /home/ldh/anaconda3/envs/gg_cnn/lib/python3.6/site-packages/nvidia/dali/libdali.so(dali::InstantiateOperator(dali::OpSpec const&)+0x264) [0x7fa7dc6ea324]\n[frame 6]: /home/ldh/anaconda3/envs/gg_cnn/lib/python3.6/site-packages/nvidia/dali/libdali.so(dali::OpGraph::InstantiateOperators()+0xa2) [0x7fa7dc6a7352]\n[frame 7]: /home/ldh/anaconda3/envs/gg_cnn/lib/python3.6/site-packages/nvidia/dali/libdali.so(dali::Pipeline::Build(std::vector<std::pair<std::string, std::string>, std::allocator<std::pair<std::string, std::string> > >)+0x9e0) [0x7fa7dc703fb0]\n[frame 8]: /home/ldh/anaconda3/envs/gg_cnn/lib/python3.6/site-packages/nvidia/dali/backend_impl.cpython-36m-x86_64-linux-gnu.so(+0x444af) [0x7fa7dd4d34af]\n[frame 9]: /home/ldh/anaconda3/envs/gg_cnn/lib/python3.6/site-packages/nvidia/dali/backend_impl.cpython-36m-x86_64-linux-gnu.so(+0x90bb4) [0x7fa7dd51fbb4]\n[frame 10]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyCFunction_FastCallDict+0x154) [0x55574efda304]\n[frame 11]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x199c5e) [0x55574f061c5e]\n[frame 12]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x30a) [0x55574f08481a]\n[frame 13]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x192f26) [0x55574f05af26]\n[frame 14]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x193f31) [0x55574f05bf31]\n[frame 15]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x199be5) [0x55574f061be5]\n[frame 16]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x30a) [0x55574f08481a]\n[frame 17]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(PyEval_EvalCodeEx+0x329) [0x55574f05ca49]\n[frame 18]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(PyEval_EvalCode+0x1c) [0x55574f05d7ec]\n[frame 19]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x1ba227) [0x55574f082227]\n[frame 20]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyCFunction_FastCallDict+0x91) [0x55574efda241]\n[frame 21]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x199b0c) [0x55574f061b0c]\n[frame 22]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x30a) [0x55574f08481a]\n[frame 23]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyGen_Send+0x256) [0x55574f064bc6]\n[frame 24]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x1445) [0x55574f085955]\n[frame 25]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyGen_Send+0x256) [0x55574f064bc6]\n[frame 26]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x1445) [0x55574f085955]\n[frame 27]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyGen_Send+0x256) [0x55574f064bc6]\n[frame 28]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyCFunction_FastCallDict+0x115) [0x55574efda2c5]\n[frame 29]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x199b0c) [0x55574f061b0c]\n[frame 30]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x30a) [0x55574f08481a]\n[frame 31]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x193cfb) [0x55574f05bcfb]\n[frame 32]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x199be5) [0x55574f061be5]\n[frame 33]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x30a) [0x55574f08481a]\n[frame 34]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x193cfb) [0x55574f05bcfb]\n[frame 35]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x199be5) [0x55574f061be5]\n[frame 36]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x30a) [0x55574f08481a]\n[frame 37]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x192f26) [0x55574f05af26]\n[frame 38]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyFunction_FastCallDict+0x3d8) [0x55574f05c628]\n[frame 39]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyObject_FastCallDict+0x26f) [0x55574efda6cf]\n[frame 40]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyObject_Call_Prepend+0x63) [0x55574efdf143]\n[frame 41]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(PyObject_Call+0x3e) [0x55574efda10e]\n[frame 42]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x1aaf) [0x55574f085fbf]\n[frame 43]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x1931f6) [0x55574f05b1f6]\n[frame 44]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x193f31) [0x55574f05bf31]\n[frame 45]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x199be5) [0x55574f061be5]\n[frame 46]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x10c9) [0x55574f0855d9]\n[frame 47]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x19c744) [0x55574f064744]\n[frame 48]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyCFunction_FastCallDict+0x91) [0x55574efda241]\n[frame 49]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x199b0c) [0x55574f061b0c]\n[frame 50]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x30a) [0x55574f08481a]\n[frame 51]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x1931f6) [0x55574f05b1f6]\n[frame 52]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x193f31) [0x55574f05bf31]\n[frame 53]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x199be5) [0x55574f061be5]\n[frame 54]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x30a) [0x55574f08481a]\n[frame 55]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x19c744) [0x55574f064744]\n[frame 56]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyCFunction_FastCallDict+0x91) [0x55574efda241]\n[frame 57]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x199b0c) [0x55574f061b0c]\n[frame 58]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x30a) [0x55574f08481a]\n[frame 59]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x1931f6) [0x55574f05b1f6]\n[frame 60]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x193f31) [0x55574f05bf31]\n[frame 61]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x199be5) [0x55574f061be5]\n[frame 62]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x30a) [0x55574f08481a]\n[frame 63]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x19c744) [0x55574f064744]\n[frame 64]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyCFunction_FastCallDict+0x91) [0x55574efda241]\n[frame 65]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x199b0c) [0x55574f061b0c]\n[frame 66]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x30a) [0x55574f08481a]\n[frame 67]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x1931f6) [0x55574f05b1f6]\n[frame 68]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyFunction_FastCallDict+0x1be) [0x55574f05c40e]\n[frame 69]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyObject_FastCallDict+0x26f) [0x55574efda6cf]\n[frame 70]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyObject_Call_Prepend+0x63) [0x55574efdf143]\n[frame 71]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(PyObject_Call+0x3e) [0x55574efda10e]\n[frame 72]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x1aaf) [0x55574f085fbf]\n[frame 73]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyGen_Send+0x134) [0x55574f064aa4]\n[frame 74]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyCFunction_FastCallDict+0x115) [0x55574efda2c5]\n[frame 75]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x199b0c) [0x55574f061b0c]\n[frame 76]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x30a) [0x55574f08481a]\n[frame 77]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x193cfb) [0x55574f05bcfb]\n[frame 78]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x199be5) [0x55574f061be5]\n[frame 79]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x30a) [0x55574f08481a]\n[frame 80]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x1931f6) [0x55574f05b1f6]\n[frame 81]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyFunction_FastCallDict+0x1be) [0x55574f05c40e]\n[frame 82]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyObject_FastCallDict+0x26f) [0x55574efda6cf]\n[frame 83]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x205c62) [0x55574f0cdc62]\n[frame 84]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyObject_FastCallDict+0x8b) [0x55574efda4eb]\n[frame 85]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x199c5e) [0x55574f061c5e]\n[frame 86]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x30a) [0x55574f08481a]\n[frame 87]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x193cfb) [0x55574f05bcfb]\n[frame 88]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x199be5) [0x55574f061be5]\n[frame 89]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x30a) [0x55574f08481a]\n[frame 90]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(PyEval_EvalCodeEx+0x966) [0x55574f05d086]\n[frame 91]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x195864) [0x55574f05d864]\n[frame 92]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(PyObject_Call+0x3e) [0x55574efda10e]\n[frame 93]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x1aaf) [0x55574f085fbf]\n[frame 94]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x193cfb) [0x55574f05bcfb]\n[frame 95]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x199be5) [0x55574f061be5]\n[frame 96]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x30a) [0x55574f08481a]\n[frame 97]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x193cfb) [0x55574f05bcfb]\n[frame 98]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x199be5) [0x55574f061be5]\n[frame 99]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x30a) [0x55574f08481a]\n\nCurrent pipeline object is no longer valid.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-95cedb1f8fe2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlabel_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpipes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCaffeReadPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_gpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdevice_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpipes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdali_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDALIGenericIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Reader\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdali_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gg_cnn/lib/python3.6/site-packages/nvidia/dali/pipeline.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, define_graph)\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefine_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_names_and_devices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_built\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Critical error when building pipeline:\nError when constructing operator: CaffeReader encountered:\n[/opt/dali/dali/operators/reader/loader/lmdb.h:52] Assert on \"mdb_env_open(mdb_env_, path.c_str(), mdb_flags, 0664) == 0\" failed: LMDB Error: Invalid argument, with file: /opt/dali_extra/db/lmdb\nStacktrace (100 entries):\n[frame 0]: /home/ldh/anaconda3/envs/gg_cnn/lib/python3.6/site-packages/nvidia/dali/libdali_operators.so(+0x3cf8ee) [0x7fa7aa7218ee]\n[frame 1]: /home/ldh/anaconda3/envs/gg_cnn/lib/python3.6/site-packages/nvidia/dali/libdali_operators.so(+0x182a83b) [0x7fa7abb7c83b]\n[frame 2]: /home/ldh/anaconda3/envs/gg_cnn/lib/python3.6/site-packages/nvidia/dali/libdali_operators.so(+0x1830cc9) [0x7fa7abb82cc9]\n[frame 3]: /home/ldh/anaconda3/envs/gg_cnn/lib/python3.6/site-packages/nvidia/dali/libdali_operators.so(std::_Function_handler<std::unique_ptr<dali::OperatorBase, std::default_delete<dali::OperatorBase> > (dali::OpSpec const&), std::unique_ptr<dali::OperatorBase, std::default_delete<dali::OperatorBase> > (*)(dali::OpSpec const&)>::_M_invoke(std::_Any_data const&, dali::OpSpec const&)+0xc) [0x7fa7aa7196bc]\n[frame 4]: /home/ldh/anaconda3/envs/gg_cnn/lib/python3.6/site-packages/nvidia/dali/libdali.so(+0x18b9e4) [0x7fa7dc6ea9e4]\n[frame 5]: /home/ldh/anaconda3/envs/gg_cnn/lib/python3.6/site-packages/nvidia/dali/libdali.so(dali::InstantiateOperator(dali::OpSpec const&)+0x264) [0x7fa7dc6ea324]\n[frame 6]: /home/ldh/anaconda3/envs/gg_cnn/lib/python3.6/site-packages/nvidia/dali/libdali.so(dali::OpGraph::InstantiateOperators()+0xa2) [0x7fa7dc6a7352]\n[frame 7]: /home/ldh/anaconda3/envs/gg_cnn/lib/python3.6/site-packages/nvidia/dali/libdali.so(dali::Pipeline::Build(std::vector<std::pair<std::string, std::string>, std::allocator<std::pair<std::string, std::string> > >)+0x9e0) [0x7fa7dc703fb0]\n[frame 8]: /home/ldh/anaconda3/envs/gg_cnn/lib/python3.6/site-packages/nvidia/dali/backend_impl.cpython-36m-x86_64-linux-gnu.so(+0x444af) [0x7fa7dd4d34af]\n[frame 9]: /home/ldh/anaconda3/envs/gg_cnn/lib/python3.6/site-packages/nvidia/dali/backend_impl.cpython-36m-x86_64-linux-gnu.so(+0x90bb4) [0x7fa7dd51fbb4]\n[frame 10]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyCFunction_FastCallDict+0x154) [0x55574efda304]\n[frame 11]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x199c5e) [0x55574f061c5e]\n[frame 12]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x30a) [0x55574f08481a]\n[frame 13]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x192f26) [0x55574f05af26]\n[frame 14]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x193f31) [0x55574f05bf31]\n[frame 15]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x199be5) [0x55574f061be5]\n[frame 16]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x30a) [0x55574f08481a]\n[frame 17]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(PyEval_EvalCodeEx+0x329) [0x55574f05ca49]\n[frame 18]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(PyEval_EvalCode+0x1c) [0x55574f05d7ec]\n[frame 19]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x1ba227) [0x55574f082227]\n[frame 20]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyCFunction_FastCallDict+0x91) [0x55574efda241]\n[frame 21]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x199b0c) [0x55574f061b0c]\n[frame 22]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x30a) [0x55574f08481a]\n[frame 23]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyGen_Send+0x256) [0x55574f064bc6]\n[frame 24]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x1445) [0x55574f085955]\n[frame 25]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyGen_Send+0x256) [0x55574f064bc6]\n[frame 26]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x1445) [0x55574f085955]\n[frame 27]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyGen_Send+0x256) [0x55574f064bc6]\n[frame 28]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyCFunction_FastCallDict+0x115) [0x55574efda2c5]\n[frame 29]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x199b0c) [0x55574f061b0c]\n[frame 30]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x30a) [0x55574f08481a]\n[frame 31]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x193cfb) [0x55574f05bcfb]\n[frame 32]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x199be5) [0x55574f061be5]\n[frame 33]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x30a) [0x55574f08481a]\n[frame 34]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x193cfb) [0x55574f05bcfb]\n[frame 35]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x199be5) [0x55574f061be5]\n[frame 36]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x30a) [0x55574f08481a]\n[frame 37]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x192f26) [0x55574f05af26]\n[frame 38]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyFunction_FastCallDict+0x3d8) [0x55574f05c628]\n[frame 39]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyObject_FastCallDict+0x26f) [0x55574efda6cf]\n[frame 40]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyObject_Call_Prepend+0x63) [0x55574efdf143]\n[frame 41]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(PyObject_Call+0x3e) [0x55574efda10e]\n[frame 42]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x1aaf) [0x55574f085fbf]\n[frame 43]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x1931f6) [0x55574f05b1f6]\n[frame 44]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x193f31) [0x55574f05bf31]\n[frame 45]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x199be5) [0x55574f061be5]\n[frame 46]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x10c9) [0x55574f0855d9]\n[frame 47]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x19c744) [0x55574f064744]\n[frame 48]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyCFunction_FastCallDict+0x91) [0x55574efda241]\n[frame 49]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x199b0c) [0x55574f061b0c]\n[frame 50]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x30a) [0x55574f08481a]\n[frame 51]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x1931f6) [0x55574f05b1f6]\n[frame 52]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x193f31) [0x55574f05bf31]\n[frame 53]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x199be5) [0x55574f061be5]\n[frame 54]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x30a) [0x55574f08481a]\n[frame 55]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x19c744) [0x55574f064744]\n[frame 56]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyCFunction_FastCallDict+0x91) [0x55574efda241]\n[frame 57]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x199b0c) [0x55574f061b0c]\n[frame 58]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x30a) [0x55574f08481a]\n[frame 59]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x1931f6) [0x55574f05b1f6]\n[frame 60]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x193f31) [0x55574f05bf31]\n[frame 61]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x199be5) [0x55574f061be5]\n[frame 62]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x30a) [0x55574f08481a]\n[frame 63]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x19c744) [0x55574f064744]\n[frame 64]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyCFunction_FastCallDict+0x91) [0x55574efda241]\n[frame 65]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x199b0c) [0x55574f061b0c]\n[frame 66]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x30a) [0x55574f08481a]\n[frame 67]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x1931f6) [0x55574f05b1f6]\n[frame 68]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyFunction_FastCallDict+0x1be) [0x55574f05c40e]\n[frame 69]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyObject_FastCallDict+0x26f) [0x55574efda6cf]\n[frame 70]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyObject_Call_Prepend+0x63) [0x55574efdf143]\n[frame 71]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(PyObject_Call+0x3e) [0x55574efda10e]\n[frame 72]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x1aaf) [0x55574f085fbf]\n[frame 73]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyGen_Send+0x134) [0x55574f064aa4]\n[frame 74]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyCFunction_FastCallDict+0x115) [0x55574efda2c5]\n[frame 75]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x199b0c) [0x55574f061b0c]\n[frame 76]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x30a) [0x55574f08481a]\n[frame 77]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x193cfb) [0x55574f05bcfb]\n[frame 78]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x199be5) [0x55574f061be5]\n[frame 79]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x30a) [0x55574f08481a]\n[frame 80]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x1931f6) [0x55574f05b1f6]\n[frame 81]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyFunction_FastCallDict+0x1be) [0x55574f05c40e]\n[frame 82]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyObject_FastCallDict+0x26f) [0x55574efda6cf]\n[frame 83]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x205c62) [0x55574f0cdc62]\n[frame 84]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyObject_FastCallDict+0x8b) [0x55574efda4eb]\n[frame 85]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x199c5e) [0x55574f061c5e]\n[frame 86]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x30a) [0x55574f08481a]\n[frame 87]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x193cfb) [0x55574f05bcfb]\n[frame 88]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x199be5) [0x55574f061be5]\n[frame 89]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x30a) [0x55574f08481a]\n[frame 90]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(PyEval_EvalCodeEx+0x966) [0x55574f05d086]\n[frame 91]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x195864) [0x55574f05d864]\n[frame 92]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(PyObject_Call+0x3e) [0x55574efda10e]\n[frame 93]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x1aaf) [0x55574f085fbf]\n[frame 94]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x193cfb) [0x55574f05bcfb]\n[frame 95]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x199be5) [0x55574f061be5]\n[frame 96]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x30a) [0x55574f08481a]\n[frame 97]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x193cfb) [0x55574f05bcfb]\n[frame 98]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(+0x199be5) [0x55574f061be5]\n[frame 99]: /home/ldh/anaconda3/envs/gg_cnn/bin/python(_PyEval_EvalFrameDefault+0x30a) [0x55574f08481a]\n\nCurrent pipeline object is no longer valid."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from nvidia.dali.plugin.pytorch import DALIGenericIterator\n",
    "\n",
    "label_range = (0, 999)\n",
    "pipes = [CaffeReadPipeline(batch_size=BATCH_SIZE, num_threads=2, device_id = device_id, num_gpus = N) for device_id in range(N)]\n",
    "pipes[0].build()\n",
    "dali_iter = DALIGenericIterator(pipes, ['data', 'label'], pipes[0].epoch_size(\"Reader\"))\n",
    "for i, data in enumerate(dali_iter):\n",
    "    if i >= ITERATIONS:\n",
    "        break\n",
    "    # Testing correctness of labels\n",
    "    for d in data:\n",
    "        label = d[\"label\"]\n",
    "        image = d[\"data\"]\n",
    "        ## labels need to be integers\n",
    "        assert(np.equal(np.mod(label, 1), 0).all())\n",
    "        ## labels need to be in range pipe_name[2]\n",
    "        assert((label >= label_range[0]).all())\n",
    "        assert((label <= label_range[1]).all())\n",
    "print(\"OK\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
